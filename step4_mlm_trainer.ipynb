{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ccda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "np.set_printoptions(threshold=2000)\n",
    "torch.set_printoptions(threshold=2000)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adb76fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758acb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = torch.load(\"data/tensor_dataset_12M.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b43331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    4,  142, 1951, 1394,  877, 5032, 2466, 2762, 3065,    2,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100,   16, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d3dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data collator\n",
    "class CustomDataCollator:\n",
    "    def __call__(self, features):\n",
    "        input_ids = torch.stack([f[0] for f in features])\n",
    "        attention_mask = torch.stack([f[1] for f in features])\n",
    "        labels = torch.stack([f[2] for f in features])\n",
    "        return {\"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"labels\": labels}\n",
    "\n",
    "# Initialize the custom data collator\n",
    "custom_dc = CustomDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb26632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12710183\n"
     ]
    }
   ],
   "source": [
    "print(len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfe2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10168146 2542037\n"
     ]
    }
   ],
   "source": [
    "# Define the ratio for train/test split\n",
    "train_size = int(0.8 * len(tds))\n",
    "eval_size = len(tds) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, eval_dataset = random_split(tds, [train_size, eval_size])\n",
    "print(len(train_dataset), len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45ea45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 128\n",
    "model_out_dir = f\"./mlm_checkpoints/CoV-RoBERTa_{EMBED_SIZE}\"\n",
    "if not os.path.exists(model_out_dir):\n",
    "    os.makedirs(model_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b835b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/model_doc/roberta#transformers.RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=10000, # defaults to 50265\n",
    "    hidden_size=768, # defaults to 768\n",
    "    max_position_embeddings=EMBED_SIZE, # defaults to 512\n",
    "    num_attention_heads=12, # defaults to 12\n",
    "    num_hidden_layers=6, # defaults to 12\n",
    "    type_vocab_size=1 # defaults to 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ec0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b209f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50909968\n"
     ]
    }
   ],
   "source": [
    "print(model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844828ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.35.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    report_to = 'tensorboard',\n",
    "    optim='adamw_torch',\n",
    "    output_dir=model_out_dir,\n",
    "    evaluation_strategy = 'steps', \n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=848, # 10168246/848 = 11991 steps  # 43 Gb GPU Memory\n",
    "    per_device_eval_batch_size=848,  # 2542062/848  = 2998  steps\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1000,\n",
    "    prediction_loss_only=True,\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=custom_dc,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535b19dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11991' max='11991' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11991/11991 8:48:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.846200</td>\n",
       "      <td>0.045501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.031457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.026570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.024655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.022686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.021051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.020579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.019163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.018140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.017714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.017182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 8:48:42.985185\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "formatted_time = str(timedelta(seconds=elapsed_time))\n",
    "\n",
    "print(f\"Elapsed time: {formatted_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adcc5a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2998' max='2998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2998/2998 23:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.016910668462514877,\n",
       " 'eval_runtime': 1437.048,\n",
       " 'eval_samples_per_second': 1768.93,\n",
       " 'eval_steps_per_second': 2.086,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d6352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f76f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
