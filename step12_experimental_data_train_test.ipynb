{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e3bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses, evaluation\n",
    "from sentence_transformers.util import SiameseDistanceMetric\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "CONSTANTS = {\n",
    "    \"VOC_NAMES\": [\"Greaney\", \"Baum\"],\n",
    "    \"LOSS_NAME\": \"ContrastiveLoss\",\n",
    "    \"NEG_SET\": \"Greaney\",\n",
    "    \"POOLING_MODE\": \"max\",\n",
    "    \"CONCAT\": None,\n",
    "    \"NUM_LABELS\": None,\n",
    "    \"CONF_THRESHOLD\": None,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 10,\n",
    "    \"LR\": 1e-4,\n",
    "    \"WD\": 1e-3,\n",
    "    \"RELU\": 0.3,\n",
    "    \"DROPOUT\": 0.5,\n",
    "    \"MARGIN\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805e9f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_checkpoints/CoV-RoBERTa_128 were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./mlm_checkpoints/CoV-RoBERTa_128 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 1280, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': True, 'pooling_mode_global_max': False, 'pooling_mode_global_avg': False, 'pooling_mode_attention': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
      "  (2): Dense({'in_features': 768, 'out_features': 230, 'bias': True, 'activation_function': 'torch.nn.modules.activation.ReLU'})\n",
      "  (3): Dropout(\n",
      "    (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#word_embedding_model = models.Transformer(model_name_or_path=\"Rostlab/prot_bert\", max_seq_length=1280)\n",
    "\n",
    "encoder = models.Transformer(model_name_or_path=\"./mlm_checkpoints/CoV-RoBERTa_128\",\n",
    "                                          max_seq_length=1280,\n",
    "                                          tokenizer_name_or_path=\"tok/\")\n",
    "\n",
    "dim = encoder.get_word_embedding_dimension() # 768\n",
    "\n",
    "pooler = models.Pooling(dim, pooling_mode = CONSTANTS[\"POOLING_MODE\"])\n",
    "\n",
    "modules = [encoder, pooler]\n",
    "\n",
    "if CONSTANTS[\"RELU\"] > 0:\n",
    "    dense = models.Dense(in_features=dim, out_features=int(dim*CONSTANTS[\"RELU\"]), activation_function=nn.ReLU())\n",
    "    modules.append(dense)\n",
    "\n",
    "if CONSTANTS[\"DROPOUT\"] > 0:\n",
    "    dropout = models.Dropout(CONSTANTS[\"DROPOUT\"])\n",
    "    modules.append(dropout)\n",
    "\n",
    "model = SentenceTransformer(modules=modules)\n",
    "\n",
    "# # Freeze initial transformer layers\n",
    "# for param in model[0].auto_model.embeddings.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in model[0].auto_model.encoder.layer[:6].parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5073d929",
   "metadata": {},
   "source": [
    "# Generate Pairs for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fec2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404 2698\n",
      "Training set length: 5102\n"
     ]
    }
   ],
   "source": [
    "sig_seq = pd.read_csv('exp_data/sig_train_val_extended.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "non_sig_seq = pd.read_csv('exp_data/non_sig_train_val_extended.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "print(len(sig_seq), len(non_sig_seq))\n",
    "from Bio import SeqIO\n",
    "wt = str(SeqIO.read('exp_data/wild_type.fasta', 'fasta').seq)\n",
    "examples = []\n",
    "\n",
    "for neg in sig_seq:\n",
    "    examples.append(InputExample(texts=[wt, neg], label=0))\n",
    "\n",
    "for pos in non_sig_seq:\n",
    "    examples.append(InputExample(texts=[wt, pos], label=1))\n",
    "\n",
    "print(\"Training set length:\", len(examples))\n",
    "# split examples list into train, validation and test sets\n",
    "random.shuffle(examples)\n",
    "train_size = int(len(examples) * 0.8)\n",
    "val_size = int(len(examples) * 0.1)\n",
    "train_examples = examples[:train_size]\n",
    "val_examples = examples[train_size:train_size + val_size]\n",
    "test_examples = examples[train_size + val_size:]\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=CONSTANTS[\"BATCH_SIZE\"])\n",
    "# val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=CONSTANTS[\"BATCH_SIZE\"])\n",
    "# test_dataloader = DataLoader(test_examples, shuffle=False, batch_size=CONSTANTS[\"BATCH_SIZE\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48aac034",
   "metadata": {},
   "source": [
    "# Generate Pairs for Zero-shot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee47a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-sig: 407 sig: 181\n",
      "Zero-shot test set length:  588\n"
     ]
    }
   ],
   "source": [
    "if CONSTANTS[\"NEG_SET\"] == \"Greaney\":\n",
    "        non_sig_seq = pd.read_csv('exp_data/non_sig_seq_greaney_filtered.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "        sig_seq = pd.read_csv('exp_data/sig_seq_greaney.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "elif CONSTANTS[\"NEG_SET\"] == \"Baum\":\n",
    "        non_sig_seq = pd.read_csv('exp_data/non_sig_seq_baum_filtered.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "        sig_seq = pd.read_csv('exp_data/sig_seq_baum.csv', header=None, names=['mutation', 'sequence'])['sequence'].tolist()\n",
    "\n",
    "print(\"non-sig:\", len(non_sig_seq), \"sig:\", len(sig_seq))\n",
    "\n",
    "zero_test_examples = []\n",
    "\n",
    "for seq in non_sig_seq:\n",
    "        zero_test_examples.append(InputExample(texts=[wt, seq], label=1))\n",
    "\n",
    "for seq in sig_seq:\n",
    "        zero_test_examples.append(InputExample(texts=[wt, seq], label=0))\n",
    "\n",
    "# shuffle the zero-shot test examples\n",
    "random.shuffle(zero_test_examples)\n",
    "\n",
    "print(\"Zero-shot test set length: \", len(zero_test_examples))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496e2710",
   "metadata": {},
   "source": [
    "# Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075fce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONSTANTS[\"LOSS_NAME\"] == \"ContrastiveLoss\":\n",
    "    train_loss = losses.ContrastiveLoss(model=model,\n",
    "                                        distance_metric=SiameseDistanceMetric.EUCLIDEAN,\n",
    "                                        margin = CONSTANTS[\"MARGIN\"])\n",
    "elif CONSTANTS[\"LOSS_NAME\"] == \"OnlineContrastiveLoss\":\n",
    "    train_loss = losses.OnlineContrastiveLoss(model=model,\n",
    "                                              distance_metric=SiameseDistanceMetric.EUCLIDEAN,\n",
    "                                              margin = CONSTANTS[\"MARGIN\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0157f63b",
   "metadata": {},
   "source": [
    "# Construct Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.BinaryClassificationEvaluator(\n",
    "    sentences1=[val_example.texts[0] for val_example in val_examples],\n",
    "    sentences2=[val_example.texts[1] for val_example in val_examples],\n",
    "    labels=[val_example.label for val_example in val_examples],\n",
    "    distance_metric=SiameseDistanceMetric.EUCLIDEAN,\n",
    "    batch_size=CONSTANTS[\"BATCH_SIZE\"],\n",
    "    margin = CONSTANTS[\"MARGIN\"],\n",
    "    show_progress_bar=False,\n",
    "    write_csv=True,\n",
    "    name='Eval')\n",
    "\n",
    "test_evaluator = evaluation.BinaryClassificationEvaluator(\n",
    "    sentences1=[test_example.texts[0] for test_example in test_examples],\n",
    "    sentences2=[test_example.texts[1] for test_example in test_examples],\n",
    "    labels=[test_example.label for test_example in test_examples],\n",
    "    batch_size=CONSTANTS['BATCH_SIZE'],\n",
    "    margin=CONSTANTS['MARGIN'],\n",
    "    show_progress_bar=False,\n",
    "    name=\"Test\")\n",
    "\n",
    "zero_test_evaluator = evaluation.BinaryClassificationEvaluator(\n",
    "    sentences1=[zero_test_example.texts[0] for zero_test_example in zero_test_examples],\n",
    "    sentences2=[zero_test_example.texts[1] for zero_test_example in zero_test_examples],\n",
    "    labels=[zero_test_example.label for zero_test_example in zero_test_examples],\n",
    "    batch_size=CONSTANTS['BATCH_SIZE'],\n",
    "    margin=CONSTANTS['MARGIN'],\n",
    "    show_progress_bar=False,\n",
    "    name=\"Zero\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24b92670",
   "metadata": {},
   "source": [
    "# Prepare Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4038e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed directory: ./exp_outputs/Greaney\n",
      "Created directory: ./exp_outputs/Greaney/checkpoints\n",
      "Created directory: ./exp_outputs/Greaney/stats\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create output directory if needed\n",
    "output_dir = f\"./exp_outputs/{CONSTANTS['NEG_SET']}\"\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(f\"Removed directory: {output_dir}\")\n",
    "\n",
    "checkpoint_dir = f\"{output_dir}/checkpoints\"\n",
    "stats_dir = f\"{output_dir}/stats\"\n",
    "\n",
    "for d in [checkpoint_dir, stats_dir]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        print(f\"Created directory: {d}\")\n",
    "\n",
    "# Dump CONSTANTS dict to file\n",
    "import json\n",
    "with open(f\"{output_dir}/constants.json\", \"w\") as f:\n",
    "    json.dump(CONSTANTS, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "267e2c8d",
   "metadata": {},
   "source": [
    "# Run Training & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a6df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC_NAMES: ['Greaney', 'Baum']\n",
      "LOSS_NAME: ContrastiveLoss\n",
      "NEG_SET: Greaney\n",
      "POOLING_MODE: max\n",
      "CONCAT: None\n",
      "NUM_LABELS: None\n",
      "CONF_THRESHOLD: None\n",
      "BATCH_SIZE: 32\n",
      "EPOCHS: 10\n",
      "LR: 0.0001\n",
      "WD: 0.001\n",
      "RELU: 0.3\n",
      "DROPOUT: 0.5\n",
      "MARGIN: 0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2698b53ecbbf4c38aef52dded49d3958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b510f8d7fc4442639574bdf79523b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 ---\n",
      "Train Loss = 6.6125   Train Accuracy = 0.7059    Train AUC = 0.5972\n",
      "Eval Loss  = 0.8175   Eval Accuracy  = 0.5863    Eval AUC  = 0.5729    (using best distance threshold   = 1.7684)\n",
      "Test Loss  = 0.7880   Test Accuracy  = 0.6008    Test AUC  = 0.6068    (using best distance threshold   = 1.6915)\n",
      "Zero Loss  = 1.2744   Zero Accuracy  = 0.6922    Zero AUC  = 0.5362    (using best distance threshold   = 3.2962)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653ecdf2e523442c93f41598afbcf38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n",
      "Train Loss = 0.0045   Train Accuracy = 0.7647    Train AUC = 0.7500\n",
      "Eval Loss  = 0.0053   Eval Accuracy  = 0.6294    Eval AUC  = 0.6336    (using best distance threshold   = 0.1258)\n",
      "Test Loss  = 0.0051   Test Accuracy  = 0.6301    Test AUC  = 0.6641    (using best distance threshold   = 0.1037)\n",
      "Zero Loss  = 0.0081   Zero Accuracy  = 0.6905    Zero AUC  = 0.5771    (using best distance threshold   = 0.3068)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a05e8e7e8514d7a89a327bf5da953d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 2 ---\n",
      "Train Loss = 0.0063   Train Accuracy = 0.8235    Train AUC = 0.7000\n",
      "Eval Loss  = 0.0051   Eval Accuracy  = 0.6157    Eval AUC  = 0.5912    (using best distance threshold   = 0.0946)\n",
      "Test Loss  = 0.0051   Test Accuracy  = 0.5988    Test AUC  = 0.6306    (using best distance threshold   = 0.0922)\n",
      "Zero Loss  = 0.0056   Zero Accuracy  = 0.6905    Zero AUC  = 0.5534    (using best distance threshold   = 0.2494)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d5bd4bec364d6ba339734a37731b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 3 ---\n",
      "Train Loss = 0.0094   Train Accuracy = 0.5294    Train AUC = 0.3542\n",
      "Eval Loss  = 0.0058   Eval Accuracy  = 0.6294    Eval AUC  = 0.6053    (using best distance threshold   = 0.0607)\n",
      "Test Loss  = 0.0061   Test Accuracy  = 0.6086    Test AUC  = 0.6313    (using best distance threshold   = 0.0597)\n",
      "Zero Loss  = 0.0047   Zero Accuracy  = 0.7245    Zero AUC  = 0.6459    (using best distance threshold   = 0.1204)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04daa7942c3649d19c78dd7a0f247c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 4 ---\n",
      "Train Loss = 0.0091   Train Accuracy = 0.7059    Train AUC = 0.7083\n",
      "Eval Loss  = 0.0036   Eval Accuracy  = 0.8000    Eval AUC  = 0.8278    (using best distance threshold   = 0.0770)\n",
      "Test Loss  = 0.0040   Test Accuracy  = 0.7867    Test AUC  = 0.8330    (using best distance threshold   = 0.0523)\n",
      "Zero Loss  = 0.0101   Zero Accuracy  = 0.7262    Zero AUC  = 0.6899    (using best distance threshold   = 0.3314)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f682f7b28a74da8bf28ccfce7d088d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 5 ---\n",
      "Train Loss = 0.0074   Train Accuracy = 0.4706    Train AUC = 0.6250\n",
      "Eval Loss  = 0.0034   Eval Accuracy  = 0.8451    Eval AUC  = 0.8560    (using best distance threshold   = 0.0415)\n",
      "Test Loss  = 0.0038   Test Accuracy  = 0.5049    Test AUC  = 0.8574    (using best distance threshold   = 0.0000)\n",
      "Zero Loss  = 0.0143   Zero Accuracy  = 0.6939    Zero AUC  = 0.6592    (using best distance threshold   = 0.4344)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10beecd15bd34c8189ee5b7ec7b6e7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 6 ---\n",
      "Train Loss = 0.0084   Train Accuracy = 0.4706    Train AUC = 0.5833\n",
      "Eval Loss  = 0.0029   Eval Accuracy  = 0.8451    Eval AUC  = 0.8986    (using best distance threshold   = 0.1337)\n",
      "Test Loss  = 0.0043   Test Accuracy  = 0.8317    Test AUC  = 0.8893    (using best distance threshold   = 0.0871)\n",
      "Zero Loss  = 0.0370   Zero Accuracy  = 0.7058    Zero AUC  = 0.6909    (using best distance threshold   = 0.4438)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2c5d5467064c288eb732c7fd688d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 7 ---\n",
      "Train Loss = 0.0083   Train Accuracy = 0.5294    Train AUC = 0.7361\n",
      "Eval Loss  = 0.0064   Eval Accuracy  = 0.4569    Eval AUC  = 0.6944    (using best distance threshold   = 0.0000)\n",
      "Test Loss  = 0.0070   Test Accuracy  = 0.5049    Test AUC  = 0.7167    (using best distance threshold   = 0.0000)\n",
      "Zero Loss  = 0.0104   Zero Accuracy  = 0.7194    Zero AUC  = 0.6902    (using best distance threshold   = 0.1218)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef5ab4d50c541c18cac947d7407b60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 8 ---\n",
      "Train Loss = 0.0049   Train Accuracy = 0.9412    Train AUC = 0.8462\n",
      "Eval Loss  = 0.0045   Eval Accuracy  = 0.7922    Eval AUC  = 0.7753    (using best distance threshold   = 0.0346)\n",
      "Test Loss  = 0.0049   Test Accuracy  = 0.7730    Test AUC  = 0.7862    (using best distance threshold   = 0.0314)\n",
      "Zero Loss  = 0.0168   Zero Accuracy  = 0.7279    Zero AUC  = 0.7443    (using best distance threshold   = 0.1785)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d5fd2626fa4c47b792fd7c90539747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 9 ---\n",
      "Train Loss = 0.0141   Train Accuracy = 0.5294    Train AUC = 0.5486\n",
      "Eval Loss  = 0.0062   Eval Accuracy  = 0.8647    Eval AUC  = 0.8924    (using best distance threshold   = 0.2038)\n",
      "Test Loss  = 0.0067   Test Accuracy  = 0.8611    Test AUC  = 0.9116    (using best distance threshold   = 0.2461)\n",
      "Zero Loss  = 0.1566   Zero Accuracy  = 0.7058    Zero AUC  = 0.6503    (using best distance threshold   = 1.1966)\n"
     ]
    }
   ],
   "source": [
    "# print CONSTANTS\n",
    "for k, v in CONSTANTS.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          tester=test_evaluator,\n",
    "          zero_shot_tester=zero_test_evaluator,\n",
    "          epochs=CONSTANTS['EPOCHS'],\n",
    "          optimizer_class=torch.optim.AdamW,\n",
    "          optimizer_params= {'lr': CONSTANTS['LR']}, # 1e-3 for CoV-RoBERTa, 1e-6 for ProtBERT\n",
    "          weight_decay=CONSTANTS['WD'], # 0.1 for CoV-RoBERTa, 0.01 for ProtBERT\n",
    "          # evaluation_steps=64,\n",
    "          output_path=output_dir,\n",
    "          #save_best_model=True,\n",
    "          #checkpoint_path=checkpoint_dir,\n",
    "          #checkpoint_save_steps=len(train_dataloader),\n",
    "          #checkpoint_save_total_limit=1000000,\n",
    "          show_progress_bar=True,\n",
    "          loss_name=CONSTANTS['LOSS_NAME'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea87d514",
   "metadata": {},
   "source": [
    "# Display Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7ff037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOSS_NAME</th>\n",
       "      <th>NEG_SET</th>\n",
       "      <th>POOLING_MODE</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>LR</th>\n",
       "      <th>WD</th>\n",
       "      <th>RELU</th>\n",
       "      <th>DROPOUT</th>\n",
       "      <th>MARGIN</th>\n",
       "      <th>MAX_TEST_ACC</th>\n",
       "      <th>MAX_ZERO_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ContrastiveLoss</td>\n",
       "      <td>Greaney</td>\n",
       "      <td>max</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.7443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LOSS_NAME  NEG_SET POOLING_MODE  BATCH_SIZE  EPOCHS      LR     WD  \\\n",
       "0  ContrastiveLoss  Greaney          max          32      10  0.0001  0.001   \n",
       "\n",
       "   RELU  DROPOUT  MARGIN  MAX_TEST_ACC  MAX_ZERO_ACC  \n",
       "0   0.3      0.5     0.2        0.9116        0.7443  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read loss values from csv:\n",
    "f_train_stats = os.path.join(stats_dir, 'Train.csv')\n",
    "f_eval_stats = os.path.join(stats_dir, 'Eval.csv')\n",
    "f_test_stats = os.path.join(stats_dir, 'Test.csv')\n",
    "f_zero_stats = os.path.join(stats_dir, 'Zero.csv')\n",
    "\n",
    "train_stats = pd.read_csv(f_train_stats)\n",
    "eval_stats = pd.read_csv(f_eval_stats)\n",
    "test_stats = pd.read_csv(f_test_stats)\n",
    "zero_stats = pd.read_csv(f_zero_stats)\n",
    "\n",
    "best_test_auc = test_stats[\"auc\"].max()\n",
    "best_zero_auc = zero_stats[\"auc\"].max()\n",
    "\n",
    "# create a dataframe with CONSTANTS and best accuracies\n",
    "df = pd.DataFrame()\n",
    "for k, v in CONSTANTS.items():\n",
    "    if k not in [\"VOC_NAMES\", \"CONCAT\", \"NUM_LABELS\", \"CONF_THRESHOLD\"]:\n",
    "        df[k] = [v] # if v is not None else [\"N/A\"]\n",
    "\n",
    "df[\"MAX_TEST_ACC\"] = best_test_auc\n",
    "df[\"MAX_ZERO_ACC\"] = best_zero_auc\n",
    "\n",
    "display(df)\n",
    "\n",
    "# save the dataframe to a csv file under stats_dir\n",
    "df.to_csv(os.path.join(stats_dir, \"summary.csv\"), index=False)\n",
    "\n",
    "# append row to global_stats.csv\n",
    "if not os.path.exists(\"global_stats.csv\") or os.path.getsize(\"global_stats.csv\") == 0:\n",
    "    df.to_csv(\"global_stats.csv\", index=False)\n",
    "else:\n",
    "    global_stats = pd.read_csv(\"global_stats.csv\")\n",
    "    global_stats = pd.concat([global_stats, df], ignore_index=True)\n",
    "    global_stats.to_csv(\"global_stats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
